{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Neural Network*\n",
    "## 4. 3층 신경망 구현하기\n",
    "\n",
    "> - NumPy 배열을 활용하여 적은 코드만으로 아래의 신경망 구현\n",
    "![](image/fig 3-15.png)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 표기법 설명\n",
    "\n",
    "\n",
    "- 이번 절에서는 $w_{12}^{(1)}나 a_1^{(1)}$ 같은 표기법 등장\n",
    "\n",
    "![](image/fig 3-16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $w_{12}^{(1)}$를 풀어 설명하면 다음과 같음\n",
    "- 0번 층의 2번째 뉴런 $x_2$에서, 1번 층의 1번째 뉴런 $a_1$으로 향할 때의 가중치\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 각 층의 신호 전달 구현하기\n",
    "\n",
    "- '1층의 첫번째 뉴런으로 가는 신호'\n",
    "- 편향 뉴런이 추가됨\n",
    "![](image/fig 3-17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $a_1^{(1)}$는 가중치를 곱한 신호 두개와 편향을 합해서 계산\n",
    "$$\n",
    "a_1^{(1)} = w_{11}^{(1)}x_1 + w_{12}^{(1)}x_2 + b_1^{(1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬 곱으로 표현시 다음과 같이 간소화 가능\n",
    "\n",
    "$$\n",
    "A^{(1)} = XW^{(1)} + B^{(1)}\n",
    "$$\n",
    "\n",
    "$$ A^{(1)} = (a_1^{(1)}, a_2^{(1)}, a_3^{(1)}),\\quad X = (x_1, x_2), \\quad B^{(1)} = (b_1^{(1)},b_2^{(1)}, b_3^{(1)})\\\\\n",
    "W^{(1)} = \\begin{bmatrix}w_{11}^{(1)} & w_{21}^{(1)} & w_{31}^{(1)}\\\\w_{12}^{(1)} & w_{22}^{(1)} & w_{32}^{(1)}\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 0.5])\n",
    "W1 = np.array([[0.1 , 0.3, 0.5], [0.2 , 0.4, 0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print(W1.shape)\n",
    "print(X.shape)\n",
    "print(B1.shape)\n",
    "\n",
    "A1 = np.dot(X, W1) + B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3, 0.7, 1.1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 바로 이어서 활성화 함수에서의 처리 필요\n",
    "- 가중치의 합 $a_1^{(1)}$을 $h()$시그모이드 함수에 따라 $z_1^{(1)}$로\n",
    "![](image/fig 3-18.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print(A1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이어서 1층에서 2층으로 가는 과정\n",
    "![](image/fig 3-19.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "W2 = np.array([[0.1, .4], [.2, .5], [.3, .6]])\n",
    "B2 = np.array([.1, .2])\n",
    "\n",
    "print(Z1.shape)\n",
    "print(W2.shape)\n",
    "print(B2.shape)\n",
    "\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "Z2 = sigmoid(A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막 층에서도 동일한 구현 반복\n",
    "- 단, 활성화 함수만 변경\n",
    "![](image/fig 3-20.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31682708, 0.69627909])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[.1, .3], [.2, .4]])\n",
    "B3 = np.array([.1, .2])\n",
    "\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "Y = identity_function(A3)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막 층에서는 항등함수로 (불필요하더라도) 출력값 구현\n",
    "- 마지막 층의 활성화 함수는 $\\sigma()$로 표시하여 은닉층의 활성화 함수 $h()$와는 다름을 명시\n",
    "- 출력층 활성화 함수는 **풀고자 하는 문제의 성질에 맞게** 정의\n",
    "- i.e. 회귀 - 항등함수, 2클래스 분류 - 시그모이드함수, 다중 분류 - 소프트맥스함수\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 구현 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[.1, .3, .5], [.2, .4, .6]])\n",
    "    network['b1'] = np.array([.1, .2, .3])\n",
    "    network['W2'] = np.array([[.1, .4], [.2, .5], [.3, .6]])\n",
    "    network['b2'] = np.array([.1, .2])\n",
    "    network['W3'] = np.array([[.1, .3], [.2, .4]])\n",
    "    network['b3'] = np.array([.1, .2])\n",
    "    \n",
    "    return network\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    \n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    \n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identity_function(a3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = init_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.3, 0.5],\n",
       "        [0.2, 0.4, 0.6]]), 'W2': array([[0.1, 0.4],\n",
       "        [0.2, 0.5],\n",
       "        [0.3, 0.6]]), 'W3': array([[0.1, 0.3],\n",
       "        [0.2, 0.4]]), 'b1': array([0.1, 0.2, 0.3]), 'b2': array([0.1, 0.2]), 'b3': array([0.1, 0.2])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 0.5])\n",
    "y = forward(network, X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- init_network() 는 가중치와 편향을 초기화하고 이들을 network 딕셔너리 변수에 저장\n",
    "- forward() 는 입력신호를 출력으로 변환하는 처리과정을 모두 구현\n",
    "- 위 함수는 순방향(입력에서 출력방향)으로 전달되는 순전파 과정을 다룸\n",
    "- 뒤쪽에서 역전파에 대해서도 알아 볼 예정\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
